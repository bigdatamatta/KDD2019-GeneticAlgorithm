{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/slremy/netsapi\n",
      "  Cloning https://github.com/slremy/netsapi to /private/var/folders/nh/8jkcnd190cd60q13l2ds0gh40000gn/T/pip-req-build-00o7n2c_\n",
      "  Running command git clone -q https://github.com/slremy/netsapi /private/var/folders/nh/8jkcnd190cd60q13l2ds0gh40000gn/T/pip-req-build-00o7n2c_\n",
      "Building wheels for collected packages: netsapi\n",
      "  Building wheel for netsapi (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /private/var/folders/nh/8jkcnd190cd60q13l2ds0gh40000gn/T/pip-ephem-wheel-cache-lnk7qhz9/wheels/9e/73/c9/86a9cc2460e11b3ce5b0a5ebd2d9d332a68afe0941659967fa\n",
      "Successfully built netsapi\n",
      "Installing collected packages: netsapi\n",
      "  Found existing installation: netsapi 1.1\n",
      "    Uninstalling netsapi-1.1:\n",
      "      Successfully uninstalled netsapi-1.1\n",
      "Successfully installed netsapi-1.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sys import exit, exc_info, argv\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "!pip install git+https://github.com/slremy/netsapi --user --upgrade\n",
    "\n",
    "from netsapi.challenge import *\n",
    "# For a given environment, evaluate a policy by applying its evaluateReward method\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "envSeqDec.evaluatePolicy(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sarsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RL(object):\n",
    "    def __init__(self, action_space, learning_rate=0.01, reward_decay=0.9, e_greedy=0.9):\n",
    "        self.actions = action_space  # a list\n",
    "        self.lr = learning_rate\n",
    "        self.gamma = reward_decay\n",
    "        self.epsilon = e_greedy\n",
    "\n",
    "        self.q_table = pd.DataFrame(columns=self.actions, dtype=np.float64)\n",
    "\n",
    "    def check_state_exist(self, state):\n",
    "        if state not in self.q_table.index:\n",
    "            # append new state to q table\n",
    "            self.q_table = self.q_table.append(\n",
    "                pd.Series(\n",
    "                    [0]*len(self.actions),\n",
    "                    index=self.q_table.columns,\n",
    "                    name=state,\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def choose_action(self, observation):\n",
    "        self.check_state_exist(observation)\n",
    "        # action selection\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            # choose best action\n",
    "            state_action = self.q_table.loc[observation, :]\n",
    "            # some actions may have the same value, randomly choose on in these actions\n",
    "            action = np.random.choice(state_action[state_action == np.max(state_action)].index)\n",
    "        else:\n",
    "            # choose random action\n",
    "            action = np.random.choice(self.actions)\n",
    "        return action\n",
    "\n",
    "    def learn(self, *args):\n",
    "        pass\n",
    "\n",
    "\n",
    "# off-policy\n",
    "class QLearningTable():\n",
    "    \n",
    "    def __init__(self, actions, learning_rate=0.01, reward_decay=0.9, e_greedy=0.9):\n",
    "        super(QLearningTable, self).__init__(actions, learning_rate, reward_decay, e_greedy)\n",
    "\n",
    "    def learn(self, s, a, r, s_):\n",
    "        self.check_state_exist(s_)\n",
    "        q_predict = self.q_table.loc[s, a]\n",
    "        if s_ != 'terminal':\n",
    "            q_target = r + self.gamma * self.q_table.loc[s_, :].max()  # next state is not terminal\n",
    "        else:\n",
    "            q_target = r  # next state is terminal\n",
    "        self.q_table.loc[s, a] += self.lr * (q_target - q_predict)  # update\n",
    "\n",
    "\n",
    "# on-policy\n",
    "class SarsaTable(RL):\n",
    "\n",
    "    def __init__(self, actions, learning_rate=0.01, reward_decay=0.9, e_greedy=0.9):\n",
    "        super(SarsaTable, self).__init__(actions, learning_rate, reward_decay, e_greedy)\n",
    "\n",
    "    def learn(self, s, a, r, s_, a_):\n",
    "        self.check_state_exist(s_)\n",
    "        q_predict = self.q_table.loc[s, a]\n",
    "        if s_ != 'terminal':\n",
    "            q_target = r + self.gamma * self.q_table.loc[s_, a_]  # next state is not terminal\n",
    "        else:\n",
    "            q_target = r  # next state is terminal\n",
    "        self.q_table.loc[s, a] += self.lr * (q_target - q_predict)  # update\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate():\n",
    "    \n",
    "    #action_space = [[0.0, 1.0], [1.0, 0.0], [0.2, 0], [0, 0.2], [0.2, 0.2]]\n",
    "    action_space = [[0.0, 0.0], [0.0, 1.0], [1.0, 0.0], [1.0, 1.0]]\n",
    "    rewards_20 = []\n",
    "    policy_20 = []\n",
    "    rewards_seq = []\n",
    "    envSeqDec = ChallengeSeqDecEnvironment(experimentCount=20000)\n",
    "\n",
    "    \n",
    "    for episode in range(20):\n",
    "        \n",
    "        # initial observation\n",
    "        envSeqDec.reset()\n",
    "        observation =1\n",
    "        rewards=0\n",
    "        policy={}\n",
    "        \n",
    "        for j in range(5):\n",
    "            # fresh env\n",
    "            # env.render()\n",
    "            # RL choose action based on observation\n",
    "            # print(observation)\n",
    "            # print(str(observation))\n",
    "            action = RL.choose_action(str(observation))\n",
    "            a=action_space[action-1]\n",
    "            #print(';;;;;;;;;;;',j,']]]]',a)\n",
    "            policy[str(j+1)]=a\n",
    "            # RL take action and get next observation and reward\n",
    "            observation_, reward, done, info = envSeqDec.evaluateAction(a)\n",
    "            if reward:\n",
    "                rewards+=reward\n",
    "            if not reward:\n",
    "                pass\n",
    "            #print(observation_, reward, done, info)\n",
    "            action_ = RL.choose_action(str(observation_))\n",
    "            \n",
    "            # RL learn from this transition\n",
    "            RL.learn(str(observation), action, reward, str(observation_), action_)\n",
    "            \n",
    "            # swap observation\n",
    "            observation = observation_\n",
    "            \n",
    "            # break while loop when end of this episode\n",
    "            if done:\n",
    "                #print('Episode:', episode + 1, ' Reward: %i' % int(rewards))\n",
    "               # print('Policy:', policy)\n",
    "                break\n",
    "                \n",
    "        #print('sequential result')\n",
    "        #seq_reward = envSeqDec.evaluatePolicy(policy)\n",
    "        #rewards_seq.append(seq_reward)\n",
    "        #print(seq_reward)\n",
    "        rewards_20.append(rewards)\n",
    "        policy_20.append(policy)\n",
    "    if(max(rewards_20)) > 450:\n",
    "        print(f'*******************************got it _{policy[rewards_20.index(max(rewards_20))]}_{max(rewards_20)}')\n",
    "    print(max(rewards_20))\n",
    "    \n",
    "    #print('Best Reward:',np.max(rewards_20))\n",
    "   # print('Best Policy:',policy_20[np.argmax(rewards_20)])\n",
    "#     x = list(range(len(rewards_20)))\n",
    "#     plt.plot(x, rewards_20)\n",
    "#     #plt.title(f'Sarsa Result action_space: {action_space} learn_rate: {learning_rate} reward_decay: {reward_decay} e_greedy: {e_greedy}')\n",
    "#     plt.title('Sarsa Result')\n",
    "#     plt.xlabel('Episodes')\n",
    "#     plt.ylabel('Rewards')\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000  Evaluations Remaining\n",
      "19999  Evaluations Remaining\n",
      "19998  Evaluations Remaining\n",
      "19997  Evaluations Remaining\n",
      "19996  Evaluations Remaining\n",
      "19995  Evaluations Remaining\n",
      "19994  Evaluations Remaining\n",
      "19993  Evaluations Remaining\n",
      "19992  Evaluations Remaining\n",
      "19991  Evaluations Remaining\n",
      "19990  Evaluations Remaining\n",
      "19989  Evaluations Remaining\n",
      "19988  Evaluations Remaining\n",
      "19987  Evaluations Remaining\n",
      "19986  Evaluations Remaining\n",
      "19985  Evaluations Remaining\n",
      "19984  Evaluations Remaining\n",
      "19983  Evaluations Remaining\n",
      "19982  Evaluations Remaining\n",
      "19981  Evaluations Remaining\n",
      "19980  Evaluations Remaining\n",
      "19979  Evaluations Remaining\n",
      "19978  Evaluations Remaining\n",
      "19977  Evaluations Remaining\n",
      "19976  Evaluations Remaining\n",
      "19975  Evaluations Remaining\n",
      "19974  Evaluations Remaining\n",
      "19973  Evaluations Remaining\n",
      "19972  Evaluations Remaining\n",
      "19971  Evaluations Remaining\n",
      "19970  Evaluations Remaining\n",
      "19969  Evaluations Remaining\n",
      "19968  Evaluations Remaining\n",
      "19967  Evaluations Remaining\n",
      "19966  Evaluations Remaining\n",
      "19965  Evaluations Remaining\n",
      "19964  Evaluations Remaining\n",
      "19963  Evaluations Remaining\n",
      "19962  Evaluations Remaining\n",
      "19961  Evaluations Remaining\n",
      "19960  Evaluations Remaining\n",
      "19959  Evaluations Remaining\n",
      "19958  Evaluations Remaining\n",
      "19957  Evaluations Remaining\n",
      "19956  Evaluations Remaining\n",
      "19955  Evaluations Remaining\n",
      "19954  Evaluations Remaining\n",
      "19953  Evaluations Remaining\n",
      "19952  Evaluations Remaining\n",
      "19951  Evaluations Remaining\n",
      "19950  Evaluations Remaining\n",
      "19949  Evaluations Remaining\n",
      "19948  Evaluations Remaining\n",
      "19947  Evaluations Remaining\n",
      "19946  Evaluations Remaining\n",
      "19945  Evaluations Remaining\n",
      "19944  Evaluations Remaining\n",
      "19943  Evaluations Remaining\n",
      "19942  Evaluations Remaining\n",
      "19941  Evaluations Remaining\n",
      "19940  Evaluations Remaining\n",
      "19939  Evaluations Remaining\n",
      "19938  Evaluations Remaining\n",
      "19937  Evaluations Remaining\n",
      "19936  Evaluations Remaining\n",
      "19935  Evaluations Remaining\n",
      "19934  Evaluations Remaining\n",
      "19933  Evaluations Remaining\n",
      "19932  Evaluations Remaining\n",
      "19931  Evaluations Remaining\n",
      "19930  Evaluations Remaining\n",
      "19929  Evaluations Remaining\n",
      "19928  Evaluations Remaining\n",
      "19927  Evaluations Remaining\n",
      "19926  Evaluations Remaining\n",
      "19925  Evaluations Remaining\n",
      "19924  Evaluations Remaining\n",
      "19923  Evaluations Remaining\n",
      "19922  Evaluations Remaining\n",
      "19921  Evaluations Remaining\n",
      "19920  Evaluations Remaining\n",
      "19919  Evaluations Remaining\n",
      "19918  Evaluations Remaining\n",
      "19917  Evaluations Remaining\n",
      "19916  Evaluations Remaining\n",
      "19915  Evaluations Remaining\n",
      "19914  Evaluations Remaining\n",
      "19913  Evaluations Remaining\n",
      "19912  Evaluations Remaining\n",
      "19911  Evaluations Remaining\n",
      "19910  Evaluations Remaining\n",
      "19909  Evaluations Remaining\n",
      "19908  Evaluations Remaining\n",
      "19907  Evaluations Remaining\n",
      "19906  Evaluations Remaining\n",
      "19905  Evaluations Remaining\n",
      "19904  Evaluations Remaining\n",
      "19903  Evaluations Remaining\n",
      "19902  Evaluations Remaining\n",
      "19901  Evaluations Remaining\n",
      "314.4446086562273\n"
     ]
    }
   ],
   "source": [
    "envSeqDec = ChallengeSeqDecEnvironment(experimentCount=20000)\n",
    "action_space = [1,2,3,4]\n",
    "RL = SarsaTable(actions=action_space,\n",
    "                learning_rate=0.01,\n",
    "                reward_decay=0.5,\n",
    "                e_greedy=0.9)\n",
    "generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find best seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_this(ii):\n",
    "    random.seed(ii)\n",
    "    print('sssssssssssssssssssssssssssssssssssssseed', ii)\n",
    "    action_space = [1,2,3,4]\n",
    "    RL = SarsaTable(actions=action_space,\n",
    "                    learning_rate=0.03,\n",
    "                    reward_decay=0.3,\n",
    "                    e_greedy=0.9)\n",
    "    generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "搜索开始时间：2019-06-27 09:49:23\n",
      "sssssssssssssssssssssssssssssssssssssseed 190\n",
      "sssssssssssssssssssssssssssssssssssssseed 195\n",
      "sssssssssssssssssssssssssssssssssssssseed 180\n",
      "sssssssssssssssssssssssssssssssssssssseed 200\n",
      "sssssssssssssssssssssssssssssssssssssseed 185\n",
      "sssssssssssssssssssssssssssssssssssssseed 165\n",
      "sssssssssssssssssssssssssssssssssssssseed 160\n",
      "sssssssssssssssssssssssssssssssssssssseed 175\n",
      "sssssssssssssssssssssssssssssssssssssseed 155\n",
      "sssssssssssssssssssssssssssssssssssssseed 150\n",
      "sssssssssssssssssssssssssssssssssssssseed 170\n",
      "sssssssssssssssssssssssssssssssssssssseed 145\n",
      "19998  Evaluations Remaining\n",
      "19998  Evaluations Remaining\n",
      "19998  Evaluations Remaining\n",
      "19998  Evaluations Remaining\n",
      "19998  Evaluations Remaining\n",
      "19998  Evaluations Remaining\n",
      "19998  Evaluations Remaining\n",
      "19998  Evaluations Remaining\n",
      "19998  Evaluations Remaining\n",
      "19998  Evaluations Remaining\n",
      "19998  Evaluations Remaining\n",
      "19998  Evaluations Remaining\n",
      "sssssssssssssssssssssssssssssssssssssseed 140\n",
      "sssssssssssssssssssssssssssssssssssssseed 135\n",
      "sssssssssssssssssssssssssssssssssssssseed 130\n",
      "19998  Evaluations Remaining\n",
      "sssssssssssssssssssssssssssssssssssssseed 125\n",
      "19998  Evaluations Remaining\n",
      "sssssssssssssssssssssssssssssssssssssseed 120\n",
      "19998  Evaluations Remaining\n",
      "sssssssssssssssssssssssssssssssssssssseed 115\n",
      "19998  Evaluations Remaining\n",
      "sssssssssssssssssssssssssssssssssssssseed 110\n",
      "19998  Evaluations Remaining\n",
      "19998  Evaluations Remaining\n",
      "sssssssssssssssssssssssssssssssssssssseed 105\n",
      "sssssssssssssssssssssssssssssssssssssseed 100\n",
      "19998  Evaluations Remaining\n",
      "sssssssssssssssssssssssssssssssssssssseed 95\n",
      "19998  Evaluations Remaining\n",
      "sssssssssssssssssssssssssssssssssssssseed 90\n",
      "19998  Evaluations Remaining\n",
      "sssssssssssssssssssssssssssssssssssssseed 85\n",
      "19998  Evaluations Remaining\n",
      "19998  Evaluations Remaining\n",
      "19998  Evaluations Remaining\n",
      "sssssssssssssssssssssssssssssssssssssseed 80\n",
      "sssssssssssssssssssssssssssssssssssssseed 75\n",
      "sssssssssssssssssssssssssssssssssssssseed 70\n",
      "sssssssssssssssssssssssssssssssssssssseed 65\n",
      "19998  Evaluations Remaining\n",
      "19998  Evaluations Remaining\n",
      "sssssssssssssssssssssssssssssssssssssseed 60\n",
      "19998  Evaluations Remaining\n",
      "sssssssssssssssssssssssssssssssssssssseed 55\n",
      "19998  Evaluations Remaining\n",
      "sssssssssssssssssssssssssssssssssssssseed 50\n",
      "19998  Evaluations Remaining\n",
      "19998  Evaluations Remaining\n",
      "sssssssssssssssssssssssssssssssssssssseed 45\n",
      "19998  Evaluations Remaining\n",
      "sssssssssssssssssssssssssssssssssssssseed 40\n",
      "19998  Evaluations Remaining\n",
      "sssssssssssssssssssssssssssssssssssssseed 35\n",
      "sssssssssssssssssssssssssssssssssssssseed 30\n",
      "19998  Evaluations Remaining\n",
      "sssssssssssssssssssssssssssssssssssssseed 25\n",
      "19998  Evaluations Remaining\n",
      "19998  Evaluations Remaining\n",
      "19998  Evaluations Remaining\n",
      "sssssssssssssssssssssssssssssssssssssseed 20\n",
      "sssssssssssssssssssssssssssssssssssssseed 15\n",
      "sssssssssssssssssssssssssssssssssssssseed 10\n",
      "sssssssssssssssssssssssssssssssssssssseed 5\n",
      "19998  Evaluations Remaining\n",
      "19998  Evaluations Remaining\n",
      "19998  Evaluations Remaining\n",
      "19998  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-230:\n",
      "Process ForkPoolWorker-240:\n",
      "Process ForkPoolWorker-239:\n",
      "Process ForkPoolWorker-236:\n",
      "Process ForkPoolWorker-233:\n",
      "Process ForkPoolWorker-241:\n",
      "Process ForkPoolWorker-232:\n",
      "Process ForkPoolWorker-238:\n",
      "Process ForkPoolWorker-231:\n",
      "Process ForkPoolWorker-237:\n",
      "Process ForkPoolWorker-235:\n",
      "Process ForkPoolWorker-234:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-a49a63ca464c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'搜索开始时间：{time.strftime(\"%Y-%m-%d %H:%M:%S\")}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0manss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'搜索结束时间：{time.strftime(\"%Y-%m-%d %H:%M:%S\")}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-a49a63ca464c>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         '''\n\u001b[0;32m--> 290\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 352, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def main():\n",
    "    \n",
    "    index = list(range(200, 0,-1))\n",
    "    pool = Pool()\n",
    "    func = run_this\n",
    "    pool.map(func, index)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    \n",
    "print(f'搜索开始时间：{time.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "anss = {}\n",
    "main()\n",
    "print(f'搜索结束时间：{time.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A good result with 2 actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "envSeqDec = ChallengeSeqDecEnvironment(experimentCount=20000)\n",
    "action_space = [1,2]\n",
    "RL = SarsaTable(actions=action_space,\n",
    "                learning_rate=0.05,\n",
    "                reward_decay=0.5,\n",
    "                e_greedy=0.9)\n",
    "generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sarsa Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RL(object):\n",
    "    def __init__(self, action_space, learning_rate=0.01, reward_decay=0.9, e_greedy=0.9):\n",
    "        self.actions = action_space  # a list\n",
    "        self.lr = learning_rate\n",
    "        self.gamma = reward_decay\n",
    "        self.epsilon = e_greedy\n",
    "\n",
    "        self.q_table = pd.DataFrame(columns=self.actions, dtype=np.float64)\n",
    "\n",
    "    def check_state_exist(self, state):\n",
    "        if state not in self.q_table.index:\n",
    "            # append new state to q table\n",
    "            self.q_table = self.q_table.append(\n",
    "                pd.Series(\n",
    "                    [0]*len(self.actions),\n",
    "                    index=self.q_table.columns,\n",
    "                    name=state,\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def choose_action(self, observation):\n",
    "        self.check_state_exist(observation)\n",
    "        # action selection\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            # choose best action\n",
    "            state_action = self.q_table.loc[observation, :]\n",
    "            # some actions may have the same value, randomly choose on in these actions\n",
    "            action = np.random.choice(state_action[state_action == np.max(state_action)].index)\n",
    "        else:\n",
    "            # choose random action\n",
    "            action = np.random.choice(self.actions)\n",
    "        return action\n",
    "\n",
    "    def learn(self, *args):\n",
    "        pass\n",
    "\n",
    "\n",
    "# backward eligibility traces\n",
    "class SarsaLambdaTable(RL):\n",
    "    def __init__(self, actions, learning_rate=0.01, reward_decay=0.9, e_greedy=0.9, trace_decay=0.9):\n",
    "        super(SarsaLambdaTable, self).__init__(actions, learning_rate, reward_decay, e_greedy)\n",
    "\n",
    "        # backward view, eligibility trace.\n",
    "        self.lambda_ = trace_decay\n",
    "        self.eligibility_trace = self.q_table.copy()\n",
    "\n",
    "    def check_state_exist(self, state):\n",
    "        if state not in self.q_table.index:\n",
    "            # append new state to q table\n",
    "            to_be_append = pd.Series(\n",
    "                    [0] * len(self.actions),\n",
    "                    index=self.q_table.columns,\n",
    "                    name=state,\n",
    "                )\n",
    "            self.q_table = self.q_table.append(to_be_append)\n",
    "\n",
    "            # also update eligibility trace\n",
    "            self.eligibility_trace = self.eligibility_trace.append(to_be_append)\n",
    "\n",
    "    def learn(self, s, a, r, s_, a_):\n",
    "        self.check_state_exist(s_)\n",
    "        q_predict = self.q_table.loc[s, a]\n",
    "        if s_ != 'terminal':\n",
    "            q_target = r + self.gamma * self.q_table.loc[s_, a_]  # next state is not terminal\n",
    "        else:\n",
    "            q_target = r  # next state is terminal\n",
    "        error = q_target - q_predict\n",
    "\n",
    "        # increase trace amount for visited state-action pair\n",
    "\n",
    "        # Method 1:\n",
    "        # self.eligibility_trace.loc[s, a] += 1\n",
    "\n",
    "        # Method 2:\n",
    "        self.eligibility_trace.loc[s, :] *= 0\n",
    "        self.eligibility_trace.loc[s, a] = 1\n",
    "\n",
    "        # Q update\n",
    "        self.q_table += self.lr * error * self.eligibility_trace\n",
    "\n",
    "        # decay eligibility trace after update\n",
    "        self.eligibility_trace *= self.gamma*self.lambda_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate():\n",
    "    step_size = 0.2\n",
    "    action_space = []\n",
    "    for step1 in range(0, int(1 / step_size) + 1):\n",
    "        for step2 in range(0, int(1 / step_size) + 1):\n",
    "            action_space.append([step1 * step_size, step2 * step_size])    \n",
    "    print(len(action_space))\n",
    "    #action_space = [[0.0, 0.8], [1.0, 0.0], [0.0, 0.2], [1.0, 1.0]]\n",
    "    rewards_20 = []\n",
    "    policy_20 = []\n",
    "    rewards_seq = []\n",
    "    policy={'1': [0,0.8], '2': [1, 0]}\n",
    "    for episode in range(20):\n",
    "        \n",
    "        # initial observation\n",
    "        envSeqDec.reset()\n",
    "        observation =1\n",
    "        rewards=0\n",
    "        \n",
    "        for j in range(20):\n",
    "\n",
    "            action = RL.choose_action(str(observation))\n",
    "            a=action_space[action-1]\n",
    "            if j == 0:\n",
    "                a = [0,0.8]\n",
    "            if j == 1:\n",
    "                a = [1,0]\n",
    "            print(';;;;;;;;;;;',j,']]]]',a)\n",
    "            policy[str(j+1)]=a    \n",
    "            # RL take action and get next observation and reward\n",
    "            observation_, reward, done, info = envSeqDec.evaluateAction(a)\n",
    "            if reward:\n",
    "                rewards+=reward\n",
    "            if not reward:\n",
    "                pass\n",
    "            print(observation_, reward, done, info)\n",
    "            action_ = RL.choose_action(str(observation_))\n",
    "            \n",
    "            # RL learn from this transition\n",
    "            RL.learn(str(observation), action, reward, str(observation_), action_)\n",
    "            \n",
    "            # swap observation\n",
    "            observation = observation_\n",
    "            \n",
    "            # break while loop when end of this episode\n",
    "            if done:\n",
    "                print('Episode:', episode + 1, ' Reward: %i' % int(rewards))\n",
    "                print('Policy:', policy)\n",
    "                break\n",
    "                \n",
    "        rewards_20.append(rewards)\n",
    "        policy_20.append(policy)\n",
    "        \n",
    "    print('Best Reward:',np.max(rewards_20))\n",
    "    print('Best Policy:',policy_20[np.argmax(rewards_20)])\n",
    "    x = list(range(len(rewards_20)))\n",
    "    plt.plot(x, rewards_20)\n",
    "    #plt.title(f'Sarsa Result action_space: {action_space} learn_rate: {learning_rate} reward_decay: {reward_decay} e_greedy: {e_greedy}')\n",
    "    plt.title('Sarsa Lamda Result')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Rewards')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      ";;;;;;;;;;; 0 ]]]] [0, 0.8]\n",
      "20000  Evaluations Remaining\n",
      "2 108.12092113311733 False {}\n",
      ";;;;;;;;;;; 1 ]]]] [1, 0]\n",
      "19999  Evaluations Remaining\n",
      "3 91.86760910188947 False {}\n",
      ";;;;;;;;;;; 2 ]]]] [1.0, 0.6000000000000001]\n",
      "19998  Evaluations Remaining\n",
      "4 31.771132733924855 False {}\n",
      ";;;;;;;;;;; 3 ]]]] [0.8, 0.8]\n",
      "19997  Evaluations Remaining\n",
      "5 9.617632117156152 False {}\n",
      ";;;;;;;;;;; 4 ]]]] [0.0, 0.4]\n",
      "19996  Evaluations Remaining\n",
      "6 17.014590840130445 True {}\n",
      "Episode: 1  Reward: 258\n",
      "Policy: {'1': [0, 0.8], '2': [1, 0], '3': [1.0, 0.6000000000000001], '4': [0.8, 0.8], '5': [0.0, 0.4]}\n",
      ";;;;;;;;;;; 0 ]]]] [0, 0.8]\n",
      "19995  Evaluations Remaining\n",
      "2 117.1484476651121 False {}\n",
      ";;;;;;;;;;; 1 ]]]] [1, 0]\n",
      "19994  Evaluations Remaining\n",
      "3 99.06038096649213 False {}\n",
      ";;;;;;;;;;; 2 ]]]] [0.0, 1.0]\n",
      "19993  Evaluations Remaining\n",
      "4 97.23487894895021 False {}\n",
      ";;;;;;;;;;; 3 ]]]] [0.6000000000000001, 0.0]\n",
      "19992  Evaluations Remaining\n",
      "5 32.47220405364665 False {}\n",
      ";;;;;;;;;;; 4 ]]]] [0.0, 0.4]\n",
      "19991  Evaluations Remaining\n",
      "6 16.182743952375933 True {}\n",
      "Episode: 2  Reward: 362\n",
      "Policy: {'1': [0, 0.8], '2': [1, 0], '3': [0.0, 1.0], '4': [0.6000000000000001, 0.0], '5': [0.0, 0.4]}\n",
      ";;;;;;;;;;; 0 ]]]] [0, 0.8]\n",
      "19990  Evaluations Remaining\n",
      "2 121.71550980358265 False {}\n",
      ";;;;;;;;;;; 1 ]]]] [1, 0]\n",
      "19989  Evaluations Remaining\n",
      "3 96.79028991428652 False {}\n",
      ";;;;;;;;;;; 2 ]]]] [0.0, 1.0]\n",
      "19988  Evaluations Remaining\n",
      "4 97.42724562766541 False {}\n",
      ";;;;;;;;;;; 3 ]]]] [0.6000000000000001, 0.0]\n",
      "19987  Evaluations Remaining\n",
      "5 32.87340861140139 False {}\n",
      ";;;;;;;;;;; 4 ]]]] [0.0, 0.4]\n",
      "19986  Evaluations Remaining\n",
      "6 15.306545542589305 True {}\n",
      "Episode: 3  Reward: 364\n",
      "Policy: {'1': [0, 0.8], '2': [1, 0], '3': [0.0, 1.0], '4': [0.6000000000000001, 0.0], '5': [0.0, 0.4]}\n",
      ";;;;;;;;;;; 0 ]]]] [0, 0.8]\n",
      "19985  Evaluations Remaining\n",
      "2 123.68734478957707 False {}\n",
      ";;;;;;;;;;; 1 ]]]] [1, 0]\n",
      "19984  Evaluations Remaining\n",
      "3 88.17666541351375 False {}\n",
      ";;;;;;;;;;; 2 ]]]] [0.0, 1.0]\n",
      "19983  Evaluations Remaining\n",
      "4 106.87298144508192 False {}\n",
      ";;;;;;;;;;; 3 ]]]] [0.6000000000000001, 0.0]\n",
      "19982  Evaluations Remaining\n",
      "5 37.05699526802343 False {}\n",
      ";;;;;;;;;;; 4 ]]]] [0.0, 0.4]\n",
      "19981  Evaluations Remaining\n",
      "6 15.454508511743839 True {}\n",
      "Episode: 4  Reward: 371\n",
      "Policy: {'1': [0, 0.8], '2': [1, 0], '3': [0.0, 1.0], '4': [0.6000000000000001, 0.0], '5': [0.0, 0.4]}\n",
      ";;;;;;;;;;; 0 ]]]] [0, 0.8]\n",
      "19980  Evaluations Remaining\n",
      "2 121.69902213840112 False {}\n",
      ";;;;;;;;;;; 1 ]]]] [1, 0]\n",
      "19979  Evaluations Remaining\n",
      "3 102.64018471251968 False {}\n",
      ";;;;;;;;;;; 2 ]]]] [0.0, 1.0]\n",
      "19978  Evaluations Remaining\n",
      "4 103.89829869744739 False {}\n",
      ";;;;;;;;;;; 3 ]]]] [0.6000000000000001, 0.4]\n",
      "19977  Evaluations Remaining\n",
      "5 34.6838795332995 False {}\n",
      ";;;;;;;;;;; 4 ]]]] [0.0, 0.4]\n",
      "19976  Evaluations Remaining\n",
      "6 20.87536389187492 True {}\n",
      "Episode: 5  Reward: 383\n",
      "Policy: {'1': [0, 0.8], '2': [1, 0], '3': [0.0, 1.0], '4': [0.6000000000000001, 0.4], '5': [0.0, 0.4]}\n",
      ";;;;;;;;;;; 0 ]]]] [0, 0.8]\n",
      "19975  Evaluations Remaining\n",
      "2 111.89539837346103 False {}\n",
      ";;;;;;;;;;; 1 ]]]] [1, 0]\n",
      "19974  Evaluations Remaining\n",
      "3 102.56166579026262 False {}\n",
      ";;;;;;;;;;; 2 ]]]] [0.0, 1.0]\n",
      "19973  Evaluations Remaining\n",
      "4 98.11157460821882 False {}\n",
      ";;;;;;;;;;; 3 ]]]] [0.8, 0.2]\n",
      "19972  Evaluations Remaining\n",
      "5 62.0033728528279 False {}\n",
      ";;;;;;;;;;; 4 ]]]] [0.0, 0.4]\n",
      "19971  Evaluations Remaining\n",
      "6 9.576223173318638 True {}\n",
      "Episode: 6  Reward: 384\n",
      "Policy: {'1': [0, 0.8], '2': [1, 0], '3': [0.0, 1.0], '4': [0.8, 0.2], '5': [0.0, 0.4]}\n",
      ";;;;;;;;;;; 0 ]]]] [0, 0.8]\n",
      "19970  Evaluations Remaining\n",
      "2 126.74454982156936 False {}\n",
      ";;;;;;;;;;; 1 ]]]] [1, 0]\n",
      "19969  Evaluations Remaining\n",
      "3 90.48383529424981 False {}\n",
      ";;;;;;;;;;; 2 ]]]] [0.0, 1.0]\n",
      "19968  Evaluations Remaining\n",
      "4 92.22366736865263 False {}\n",
      ";;;;;;;;;;; 3 ]]]] [0.6000000000000001, 0.0]\n",
      "19967  Evaluations Remaining\n",
      "5 35.55129698383051 False {}\n",
      ";;;;;;;;;;; 4 ]]]] [0.0, 0.4]\n",
      "19966  Evaluations Remaining\n",
      "6 16.23540615366269 True {}\n",
      "Episode: 7  Reward: 361\n",
      "Policy: {'1': [0, 0.8], '2': [1, 0], '3': [0.0, 1.0], '4': [0.6000000000000001, 0.0], '5': [0.0, 0.4]}\n",
      ";;;;;;;;;;; 0 ]]]] [0, 0.8]\n",
      "19965  Evaluations Remaining\n",
      "2 124.36173131393983 False {}\n",
      ";;;;;;;;;;; 1 ]]]] [1, 0]\n",
      "19964  Evaluations Remaining\n",
      "3 99.88343217833696 False {}\n",
      ";;;;;;;;;;; 2 ]]]] [1.0, 0.6000000000000001]\n",
      "19963  Evaluations Remaining\n",
      "4 38.453355391816416 False {}\n",
      ";;;;;;;;;;; 3 ]]]] [0.6000000000000001, 0.0]\n",
      "19962  Evaluations Remaining\n",
      "5 0.18320001416196918 False {}\n",
      ";;;;;;;;;;; 4 ]]]] [0.0, 0.4]\n",
      "19961  Evaluations Remaining\n",
      "6 15.762987786118043 True {}\n",
      "Episode: 8  Reward: 278\n",
      "Policy: {'1': [0, 0.8], '2': [1, 0], '3': [1.0, 0.6000000000000001], '4': [0.6000000000000001, 0.0], '5': [0.0, 0.4]}\n",
      ";;;;;;;;;;; 0 ]]]] [0, 0.8]\n",
      "19960  Evaluations Remaining\n",
      "2 113.42474980827832 False {}\n",
      ";;;;;;;;;;; 1 ]]]] [1, 0]\n",
      "19959  Evaluations Remaining\n",
      "3 94.87213046746139 False {}\n",
      ";;;;;;;;;;; 2 ]]]] [0.0, 1.0]\n",
      "19958  Evaluations Remaining\n",
      "4 91.4258547242665 False {}\n",
      ";;;;;;;;;;; 3 ]]]] [0.6000000000000001, 0.0]\n",
      "19957  Evaluations Remaining\n",
      "5 32.35662458277248 False {}\n",
      ";;;;;;;;;;; 4 ]]]] [0.6000000000000001, 0.2]\n",
      "19956  Evaluations Remaining\n",
      "6 -46.08589541698637 True {}\n",
      "Episode: 9  Reward: 285\n",
      "Policy: {'1': [0, 0.8], '2': [1, 0], '3': [0.0, 1.0], '4': [0.6000000000000001, 0.0], '5': [0.6000000000000001, 0.2]}\n",
      ";;;;;;;;;;; 0 ]]]] [0, 0.8]\n",
      "19955  Evaluations Remaining\n",
      "2 105.83196076952787 False {}\n",
      ";;;;;;;;;;; 1 ]]]] [1, 0]\n",
      "19954  Evaluations Remaining\n",
      "3 94.50278487802392 False {}\n",
      ";;;;;;;;;;; 2 ]]]] [0.0, 1.0]\n",
      "19953  Evaluations Remaining\n",
      "4 95.5401291358696 False {}\n",
      ";;;;;;;;;;; 3 ]]]] [0.6000000000000001, 0.0]\n",
      "19952  Evaluations Remaining\n",
      "5 36.93502877035609 False {}\n",
      ";;;;;;;;;;; 4 ]]]] [0.0, 0.4]\n",
      "19951  Evaluations Remaining\n",
      "6 13.73392827385047 True {}\n",
      "Episode: 10  Reward: 346\n",
      "Policy: {'1': [0, 0.8], '2': [1, 0], '3': [0.0, 1.0], '4': [0.6000000000000001, 0.0], '5': [0.0, 0.4]}\n",
      ";;;;;;;;;;; 0 ]]]] [0, 0.8]\n",
      "19950  Evaluations Remaining\n",
      "2 107.7251859213374 False {}\n",
      ";;;;;;;;;;; 1 ]]]] [1, 0]\n",
      "19949  Evaluations Remaining\n",
      "3 87.41555467378191 False {}\n",
      ";;;;;;;;;;; 2 ]]]] [0.0, 1.0]\n",
      "19948  Evaluations Remaining\n",
      "4 91.97109442938819 False {}\n",
      ";;;;;;;;;;; 3 ]]]] [0.6000000000000001, 0.0]\n",
      "19947  Evaluations Remaining\n",
      "5 38.056489540276154 False {}\n",
      ";;;;;;;;;;; 4 ]]]] [0.0, 0.4]\n",
      "19946  Evaluations Remaining\n",
      "6 15.47341862266579 True {}\n",
      "Episode: 11  Reward: 340\n",
      "Policy: {'1': [0, 0.8], '2': [1, 0], '3': [0.0, 1.0], '4': [0.6000000000000001, 0.0], '5': [0.0, 0.4]}\n",
      ";;;;;;;;;;; 0 ]]]] [0, 0.8]\n",
      "19945  Evaluations Remaining\n",
      "2 113.54226636352305 False {}\n",
      ";;;;;;;;;;; 1 ]]]] [1, 0]\n",
      "19944  Evaluations Remaining\n",
      "3 93.26659848440917 False {}\n",
      ";;;;;;;;;;; 2 ]]]] [0.6000000000000001, 0.0]\n",
      "19943  Evaluations Remaining\n",
      "4 -0.2694741813023427 False {}\n",
      ";;;;;;;;;;; 3 ]]]] [0.6000000000000001, 0.0]\n",
      "19942  Evaluations Remaining\n",
      "5 1.2939463932467414 False {}\n",
      ";;;;;;;;;;; 4 ]]]] [0.0, 0.4]\n",
      "19941  Evaluations Remaining\n",
      "6 14.988528828471836 True {}\n",
      "Episode: 12  Reward: 222\n",
      "Policy: {'1': [0, 0.8], '2': [1, 0], '3': [0.6000000000000001, 0.0], '4': [0.6000000000000001, 0.0], '5': [0.0, 0.4]}\n",
      ";;;;;;;;;;; 0 ]]]] [0, 0.8]\n",
      "19940  Evaluations Remaining\n",
      "2 116.21120652543672 False {}\n",
      ";;;;;;;;;;; 1 ]]]] [1, 0]\n",
      "19939  Evaluations Remaining\n",
      "3 95.53647182684307 False {}\n",
      ";;;;;;;;;;; 2 ]]]] [0.0, 1.0]\n",
      "19938  Evaluations Remaining\n",
      "4 108.76950233617448 False {}\n",
      ";;;;;;;;;;; 3 ]]]] [0.6000000000000001, 0.0]\n",
      "19937  Evaluations Remaining\n",
      "5 35.964182629415184 False {}\n",
      ";;;;;;;;;;; 4 ]]]] [0.0, 0.4]\n",
      "19936  Evaluations Remaining\n",
      "6 14.877006805971824 True {}\n",
      "Episode: 13  Reward: 371\n",
      "Policy: {'1': [0, 0.8], '2': [1, 0], '3': [0.0, 1.0], '4': [0.6000000000000001, 0.0], '5': [0.0, 0.4]}\n",
      ";;;;;;;;;;; 0 ]]]] [0, 0.8]\n",
      "19935  Evaluations Remaining\n",
      "2 111.71236115758373 False {}\n",
      ";;;;;;;;;;; 1 ]]]] [1, 0]\n",
      "19934  Evaluations Remaining\n",
      "3 92.27779355876218 False {}\n",
      ";;;;;;;;;;; 2 ]]]] [0.0, 1.0]\n",
      "19933  Evaluations Remaining\n",
      "4 101.55951415043312 False {}\n",
      ";;;;;;;;;;; 3 ]]]] [0.6000000000000001, 0.0]\n",
      "19932  Evaluations Remaining\n",
      "5 35.26056854885726 False {}\n",
      ";;;;;;;;;;; 4 ]]]] [0.2, 0.0]\n",
      "19931  Evaluations Remaining\n",
      "6 -0.05420235312810728 True {}\n",
      "Episode: 14  Reward: 340\n",
      "Policy: {'1': [0, 0.8], '2': [1, 0], '3': [0.0, 1.0], '4': [0.6000000000000001, 0.0], '5': [0.2, 0.0]}\n",
      ";;;;;;;;;;; 0 ]]]] [0, 0.8]\n",
      "19930  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 115.13628131148172 False {}\n",
      ";;;;;;;;;;; 1 ]]]] [1, 0]\n",
      "19929  Evaluations Remaining\n",
      "3 91.24201599617506 False {}\n",
      ";;;;;;;;;;; 2 ]]]] [0.6000000000000001, 0.6000000000000001]\n",
      "19928  Evaluations Remaining\n",
      "4 33.94883259730819 False {}\n",
      ";;;;;;;;;;; 3 ]]]] [0.2, 1.0]\n",
      "19927  Evaluations Remaining\n",
      "5 10.002887182656133 False {}\n",
      ";;;;;;;;;;; 4 ]]]] [0.0, 0.4]\n",
      "19926  Evaluations Remaining\n",
      "6 -0.2555711590993841 True {}\n",
      "Episode: 15  Reward: 250\n",
      "Policy: {'1': [0, 0.8], '2': [1, 0], '3': [0.6000000000000001, 0.6000000000000001], '4': [0.2, 1.0], '5': [0.0, 0.4]}\n",
      ";;;;;;;;;;; 0 ]]]] [0, 0.8]\n",
      "19925  Evaluations Remaining\n",
      "2 115.86651478409655 False {}\n",
      ";;;;;;;;;;; 1 ]]]] [1, 0]\n",
      "19924  Evaluations Remaining\n",
      "3 97.83948983507395 False {}\n",
      ";;;;;;;;;;; 2 ]]]] [0.0, 1.0]\n",
      "19923  Evaluations Remaining\n",
      "4 98.18701148898859 False {}\n",
      ";;;;;;;;;;; 3 ]]]] [0.6000000000000001, 0.0]\n",
      "19922  Evaluations Remaining\n",
      "5 37.91728570441094 False {}\n",
      ";;;;;;;;;;; 4 ]]]] [0.8, 0.0]\n",
      "19921  Evaluations Remaining\n",
      "6 4.422031166506626 True {}\n",
      "Episode: 16  Reward: 354\n",
      "Policy: {'1': [0, 0.8], '2': [1, 0], '3': [0.0, 1.0], '4': [0.6000000000000001, 0.0], '5': [0.8, 0.0]}\n",
      ";;;;;;;;;;; 0 ]]]] [0, 0.8]\n",
      "19920  Evaluations Remaining\n",
      "2 107.80057276970629 False {}\n",
      ";;;;;;;;;;; 1 ]]]] [1, 0]\n",
      "19919  Evaluations Remaining\n",
      "3 102.17880263489717 False {}\n",
      ";;;;;;;;;;; 2 ]]]] [0.0, 1.0]\n",
      "19918  Evaluations Remaining\n",
      "4 91.28489918119512 False {}\n",
      ";;;;;;;;;;; 3 ]]]] [0.6000000000000001, 0.0]\n",
      "19917  Evaluations Remaining\n",
      "5 33.30385376858557 False {}\n",
      ";;;;;;;;;;; 4 ]]]] [0.0, 0.4]\n",
      "19916  Evaluations Remaining\n",
      "6 16.573411250757758 True {}\n",
      "Episode: 17  Reward: 351\n",
      "Policy: {'1': [0, 0.8], '2': [1, 0], '3': [0.0, 1.0], '4': [0.6000000000000001, 0.0], '5': [0.0, 0.4]}\n",
      ";;;;;;;;;;; 0 ]]]] [0, 0.8]\n",
      "19915  Evaluations Remaining\n",
      "2 123.79347822156485 False {}\n",
      ";;;;;;;;;;; 1 ]]]] [1, 0]\n",
      "19914  Evaluations Remaining\n",
      "3 91.79521556271419 False {}\n",
      ";;;;;;;;;;; 2 ]]]] [0.0, 1.0]\n",
      "19913  Evaluations Remaining\n",
      "4 103.62548781205764 False {}\n",
      ";;;;;;;;;;; 3 ]]]] [0.6000000000000001, 0.0]\n",
      "19912  Evaluations Remaining\n",
      "5 36.87715113153199 False {}\n",
      ";;;;;;;;;;; 4 ]]]] [0.0, 0.4]\n",
      "19911  Evaluations Remaining\n",
      "6 14.452586070380224 True {}\n",
      "Episode: 18  Reward: 370\n",
      "Policy: {'1': [0, 0.8], '2': [1, 0], '3': [0.0, 1.0], '4': [0.6000000000000001, 0.0], '5': [0.0, 0.4]}\n",
      ";;;;;;;;;;; 0 ]]]] [0, 0.8]\n",
      "19910  Evaluations Remaining\n",
      "2 115.70803757520258 False {}\n",
      ";;;;;;;;;;; 1 ]]]] [1, 0]\n",
      "19909  Evaluations Remaining\n",
      "3 91.6126894033199 False {}\n",
      ";;;;;;;;;;; 2 ]]]] [0.0, 0.2]\n",
      "19908  Evaluations Remaining\n",
      "4 40.81212396138092 False {}\n",
      ";;;;;;;;;;; 3 ]]]] [0.6000000000000001, 0.0]\n",
      "19907  Evaluations Remaining\n",
      "5 38.58283206139283 False {}\n",
      ";;;;;;;;;;; 4 ]]]] [0.0, 0.4]\n",
      "19906  Evaluations Remaining\n",
      "6 13.488489724350384 True {}\n",
      "Episode: 19  Reward: 300\n",
      "Policy: {'1': [0, 0.8], '2': [1, 0], '3': [0.0, 0.2], '4': [0.6000000000000001, 0.0], '5': [0.0, 0.4]}\n",
      ";;;;;;;;;;; 0 ]]]] [0, 0.8]\n",
      "19905  Evaluations Remaining\n",
      "2 114.8955833062764 False {}\n",
      ";;;;;;;;;;; 1 ]]]] [1, 0]\n",
      "19904  Evaluations Remaining\n",
      "3 102.29333970540414 False {}\n",
      ";;;;;;;;;;; 2 ]]]] [0.0, 1.0]\n",
      "19903  Evaluations Remaining\n",
      "4 105.51841780792566 False {}\n",
      ";;;;;;;;;;; 3 ]]]] [0.6000000000000001, 0.0]\n",
      "19902  Evaluations Remaining\n",
      "5 38.229733264833925 False {}\n",
      ";;;;;;;;;;; 4 ]]]] [0.0, 0.4]\n",
      "19901  Evaluations Remaining\n",
      "6 13.735317137781763 True {}\n",
      "Episode: 20  Reward: 374\n",
      "Policy: {'1': [0, 0.8], '2': [1, 0], '3': [0.0, 1.0], '4': [0.6000000000000001, 0.0], '5': [0.0, 0.4]}\n",
      "Best Reward: 384.148234798089\n",
      "Best Policy: {'1': [0, 0.8], '2': [1, 0], '3': [0.0, 1.0], '4': [0.6000000000000001, 0.0], '5': [0.0, 0.4]}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#action_space = [[0.0, 1.0], [1.0, 0.0], [0.0, 0.0], [1.0, 1.0]]\n",
    "\n",
    "        \n",
    "envSeqDec = ChallengeSeqDecEnvironment(experimentCount=20000)\n",
    "action_space = list(range(1, 37)) # Using two actions can get steady 490 - 500 result.\n",
    "RL = SarsaLambdaTable(actions=action_space,\n",
    "            learning_rate=0.3,\n",
    "            reward_decay=0.5,\n",
    "            e_greedy=0.8)\n",
    "generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
